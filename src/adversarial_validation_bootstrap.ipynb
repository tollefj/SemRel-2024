{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from util import get_data\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import auc, roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "from sentence_transformers import CrossEncoder, InputExample\n",
    "from sentence_transformers.cross_encoder.evaluation import (\n",
    "    CESoftmaxAccuracyEvaluator,\n",
    ")\n",
    "from sklearn.metrics import auc, roc_curve\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "def make_data(train, test):\n",
    "    train_examples = []\n",
    "    test_examples = []\n",
    "    for i, row in train.iterrows():\n",
    "        train_examples.append(\n",
    "            InputExample(texts=[row[\"s1\"], row[\"s2\"]], label=row[\"label\"])\n",
    "        )\n",
    "    for i, row in test.iterrows():\n",
    "        test_examples.append(\n",
    "            InputExample(texts=[row[\"s1\"], row[\"s2\"]], label=row[\"label\"])\n",
    "        )\n",
    "\n",
    "    return train_examples, test_examples\n",
    "\n",
    "\n",
    "def separate_splits(\n",
    "    lang, adversarial_train, adversarial_test, model_name=\"xlm-roberta-base\"\n",
    "):\n",
    "    train_examples, test_examples = make_data(adversarial_train, adversarial_test)\n",
    "\n",
    "    train_dataloader = DataLoader(train_examples, shuffle=True, batch_size=32)\n",
    "    evaluation = CESoftmaxAccuracyEvaluator.from_input_examples(\n",
    "        test_examples, name=\"adversarial_test\"\n",
    "    )\n",
    "    model = CrossEncoder(model_name, num_labels=2)\n",
    "    epochs = 4\n",
    "    model.fit(\n",
    "        train_dataloader=train_dataloader,\n",
    "        evaluator=evaluation,\n",
    "        # optimizer_params={\n",
    "        #     \"lr\": 1e-5,\n",
    "        # },\n",
    "        epochs=epochs,\n",
    "        warmup_steps=len(train_dataloader) * 0.1 * epochs,\n",
    "        show_progress_bar=False,\n",
    "    )\n",
    "    model_predictions = model.predict([example.texts for example in test_examples])\n",
    "    model_predictions = [1 if pred[0] > pred[1] else 0 for pred in model_predictions]\n",
    "    fpr, tpr, _ = roc_curve(\n",
    "        [example.label for example in test_examples], model_predictions\n",
    "    )\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    plot_auc(fpr, tpr, roc_auc, lang=lang)\n",
    "    return roc_auc\n",
    "\n",
    "def plot_auc(fpr, tpr, roc_auc, lang):\n",
    "    plt.figure()\n",
    "    lw = 2\n",
    "    plt.plot(\n",
    "        fpr,\n",
    "        tpr,\n",
    "        color=\"darkorange\",\n",
    "        lw=lw,\n",
    "        label=\"ROC curve (area = %0.2f)\" % roc_auc,\n",
    "    )\n",
    "    plt.plot([0, 1], [0, 1], color=\"navy\", lw=lw, linestyle=\"--\")\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel(\"False Positive Rate\")\n",
    "    plt.ylabel(\"True Positive Rate\")\n",
    "    plt.title(f\"ROC curve for {lang}\")\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "lang = \"eng\"\n",
    "\n",
    "train = get_data(lang=lang, train=True)\n",
    "test = get_data(lang=lang, test=True)\n",
    "test = test[[\"s1\", \"s2\"]]\n",
    "test[\"label\"] = 1\n",
    "\n",
    "# iteratively move through test data and\n",
    "# find its distribution overlap in the test data\n",
    "window_size = 200\n",
    "num_windows = len(train) // window_size\n",
    "print(f\"Number of windows: {num_windows}\")\n",
    "\n",
    "distribution_scores = {}\n",
    "for window_idx in tqdm(range(num_windows + 1)):\n",
    "    train_window = train[window_idx * window_size : (window_idx + 1) * window_size]\n",
    "    ids = train_window[\"PairID\"].values\n",
    "    train_window = train_window[[\"s1\", \"s2\"]]\n",
    "    train_window[\"label\"] = 0\n",
    "    df = pd.concat([train_window, test])\n",
    "    train_window, test_window = train_test_split(df, test_size=0.3)\n",
    "    roc_auc = separate_splits(\n",
    "        lang, train_window, test_window, model_name=\"roberta-base\"\n",
    "    )\n",
    "    window_range = f\"{ids[0]}-{ids[-1]}\"\n",
    "    distribution_scores[window_range] = roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ENG-train-0000-ENG-train-0199': 0.26305990581535427,\n",
       " 'ENG-train-0200-ENG-train-0399': 0.5,\n",
       " 'ENG-train-0400-ENG-train-0599': 0.5,\n",
       " 'ENG-train-0600-ENG-train-0799': 0.5,\n",
       " 'ENG-train-0800-ENG-train-0999': 0.42578157392818644,\n",
       " 'ENG-train-1000-ENG-train-1199': 0.4627487575685236,\n",
       " 'ENG-train-1200-ENG-train-1399': 0.5,\n",
       " 'ENG-train-1400-ENG-train-1599': 0.49122807017543857,\n",
       " 'ENG-train-1600-ENG-train-1799': 0.41319261768976623,\n",
       " 'ENG-train-1800-ENG-train-1999': 0.453024453024453,\n",
       " 'ENG-train-2000-ENG-train-2199': 0.35012191405059434,\n",
       " 'ENG-train-2200-ENG-train-2399': 0.3660545905707196,\n",
       " 'ENG-train-2400-ENG-train-2599': 0.4396551724137931,\n",
       " 'ENG-train-2600-ENG-train-2799': 0.33656330749354013,\n",
       " 'ENG-train-2800-ENG-train-2999': 0.3663194444444445,\n",
       " 'ENG-train-3000-ENG-train-3199': 0.35657240825538744,\n",
       " 'ENG-train-3200-ENG-train-3399': 0.3728957625010366,\n",
       " 'ENG-train-3400-ENG-train-3599': 0.3496919277888327,\n",
       " 'ENG-train-3600-ENG-train-3799': 0.36065573770491804,\n",
       " 'ENG-train-3800-ENG-train-3999': 0.3994030351705785,\n",
       " 'ENG-train-4000-ENG-train-4199': 0.40228119278604346,\n",
       " 'ENG-train-4200-ENG-train-4399': 0.31449737479322,\n",
       " 'ENG-train-4400-ENG-train-4599': 0.34935897435897434,\n",
       " 'ENG-train-4600-ENG-train-4799': 0.3677310052199395,\n",
       " 'ENG-train-4800-ENG-train-4999': 0.3474358974358974,\n",
       " 'ENG-train-5000-ENG-train-5199': 0.3759119861030689,\n",
       " 'ENG-train-5200-ENG-train-5399': 0.3732471999294471,\n",
       " 'ENG-train-5400-ENG-train-5499': 0.3406369426751592}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distribution_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ENG-train-0200-ENG-train-0399\n",
      "ENG-train-0400-ENG-train-0599\n",
      "ENG-train-0600-ENG-train-0799\n",
      "ENG-train-0800-ENG-train-0999\n",
      "ENG-train-1000-ENG-train-1199\n",
      "ENG-train-1200-ENG-train-1399\n",
      "ENG-train-1400-ENG-train-1599\n",
      "ENG-train-1600-ENG-train-1799\n",
      "ENG-train-1800-ENG-train-1999\n",
      "ENG-train-2400-ENG-train-2599\n",
      "ENG-train-4000-ENG-train-4199\n"
     ]
    }
   ],
   "source": [
    "overlapping_dist = {\n",
    "    k: v for k, v in distribution_scores.items() if v >= 0.4\n",
    "}\n",
    "good_samples = overlapping_dist.keys()\n",
    "for sample in overlapping_dist.keys():\n",
    "    print(sample)\n",
    "    parts = sample.split(\"-\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 1999)\n",
      "(2400, 2599)\n",
      "(4000, 4199)\n"
     ]
    }
   ],
   "source": [
    "sorted_samples = sorted(\n",
    "    overlapping_dist.keys(), key=lambda x: (int(x.split(\"-\")[2]), int(x.split(\"-\")[5]))\n",
    ")\n",
    "good_pairs = []\n",
    "# Initialize the start and end of the current block\n",
    "current_start = None\n",
    "current_end = None\n",
    "\n",
    "for sample in sorted_samples:\n",
    "    parts = sample.split(\"-\")\n",
    "    _from = int(parts[2])\n",
    "    _to = int(parts[5])\n",
    "\n",
    "    if current_start is None:\n",
    "        current_start = _from\n",
    "        current_end = _to\n",
    "    elif _from == current_end + 1:\n",
    "        current_end = _to\n",
    "    else:\n",
    "        good_pairs.append((current_start, current_end))\n",
    "        current_start = _from\n",
    "        current_end = _to\n",
    "\n",
    "if current_start is not None:\n",
    "    good_pairs.append((current_start, current_end))\n",
    "\n",
    "for pair in good_pairs:\n",
    "    print(pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "numbers = []\n",
    "for start, end in good_pairs:\n",
    "    numbers.extend(range(start, end + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PairID</th>\n",
       "      <th>Score</th>\n",
       "      <th>s1</th>\n",
       "      <th>s2</th>\n",
       "      <th>simple_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>ENG-train-0200</td>\n",
       "      <td>0.91</td>\n",
       "      <td>You try to forget everything good, and remembe...</td>\n",
       "      <td>you just try to forget everything good, and re...</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>ENG-train-0201</td>\n",
       "      <td>0.91</td>\n",
       "      <td>It is up to your boyfriend to tell her.</td>\n",
       "      <td>Your bf should be the on telling her.</td>\n",
       "      <td>201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>ENG-train-0202</td>\n",
       "      <td>0.91</td>\n",
       "      <td>I'll talk to the son of a- Foyle!</td>\n",
       "      <td>I want to talk to this son-of-a-Foyle!</td>\n",
       "      <td>202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>ENG-train-0203</td>\n",
       "      <td>0.91</td>\n",
       "      <td>The orchestra 's reputation increased most pro...</td>\n",
       "      <td>Serge Koussevitzky was their conductor for man...</td>\n",
       "      <td>203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>ENG-train-0204</td>\n",
       "      <td>0.91</td>\n",
       "      <td>I definitely believe that there is a 'special ...</td>\n",
       "      <td>I think their is a 'special someone' for every...</td>\n",
       "      <td>204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4195</th>\n",
       "      <td>ENG-train-4195</td>\n",
       "      <td>0.31</td>\n",
       "      <td>Because I'm against common core, common crooks...</td>\n",
       "      <td>#BENGHAZI WAIT DID I SAY \"THANK GOD?\" VOTERS? ...</td>\n",
       "      <td>4195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4196</th>\n",
       "      <td>ENG-train-4196</td>\n",
       "      <td>0.31</td>\n",
       "      <td>It varies from place to place.</td>\n",
       "      <td>That is a good place to start.</td>\n",
       "      <td>4196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4197</th>\n",
       "      <td>ENG-train-4197</td>\n",
       "      <td>0.31</td>\n",
       "      <td>I'm pitchingthis at Fox in half an hour.</td>\n",
       "      <td>Which means what, half an hour?</td>\n",
       "      <td>4197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4198</th>\n",
       "      <td>ENG-train-4198</td>\n",
       "      <td>0.31</td>\n",
       "      <td>We live in a world where people care more abou...</td>\n",
       "      <td>So unfortunate #thebriefcase @cbs. Adoption is...</td>\n",
       "      <td>4198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4199</th>\n",
       "      <td>ENG-train-4199</td>\n",
       "      <td>0.31</td>\n",
       "      <td>Bleeding to death after brutal mugging on the ...</td>\n",
       "      <td>Alyssa doesn't take so good to being transform...</td>\n",
       "      <td>4199</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2200 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              PairID  Score  \\\n",
       "200   ENG-train-0200   0.91   \n",
       "201   ENG-train-0201   0.91   \n",
       "202   ENG-train-0202   0.91   \n",
       "203   ENG-train-0203   0.91   \n",
       "204   ENG-train-0204   0.91   \n",
       "...              ...    ...   \n",
       "4195  ENG-train-4195   0.31   \n",
       "4196  ENG-train-4196   0.31   \n",
       "4197  ENG-train-4197   0.31   \n",
       "4198  ENG-train-4198   0.31   \n",
       "4199  ENG-train-4199   0.31   \n",
       "\n",
       "                                                     s1  \\\n",
       "200   You try to forget everything good, and remembe...   \n",
       "201             It is up to your boyfriend to tell her.   \n",
       "202                   I'll talk to the son of a- Foyle!   \n",
       "203   The orchestra 's reputation increased most pro...   \n",
       "204   I definitely believe that there is a 'special ...   \n",
       "...                                                 ...   \n",
       "4195  Because I'm against common core, common crooks...   \n",
       "4196                     It varies from place to place.   \n",
       "4197           I'm pitchingthis at Fox in half an hour.   \n",
       "4198  We live in a world where people care more abou...   \n",
       "4199  Bleeding to death after brutal mugging on the ...   \n",
       "\n",
       "                                                     s2  simple_id  \n",
       "200   you just try to forget everything good, and re...        200  \n",
       "201               Your bf should be the on telling her.        201  \n",
       "202              I want to talk to this son-of-a-Foyle!        202  \n",
       "203   Serge Koussevitzky was their conductor for man...        203  \n",
       "204   I think their is a 'special someone' for every...        204  \n",
       "...                                                 ...        ...  \n",
       "4195  #BENGHAZI WAIT DID I SAY \"THANK GOD?\" VOTERS? ...       4195  \n",
       "4196                     That is a good place to start.       4196  \n",
       "4197                    Which means what, half an hour?       4197  \n",
       "4198  So unfortunate #thebriefcase @cbs. Adoption is...       4198  \n",
       "4199  Alyssa doesn't take so good to being transform...       4199  \n",
       "\n",
       "[2200 rows x 5 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from util import get_data\n",
    "lang = \"eng\"\n",
    "# iterate the training set and create a new training set with only in-distribution samples\n",
    "train = get_data(lang=lang, train=True, clean=False)\n",
    "train[\"simple_id\"] = train[\"PairID\"].apply(lambda x: int(x.split(\"-\")[-1]))\n",
    "train = train[train[\"simple_id\"].isin(numbers)]\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.drop(columns=[\"simple_id\"])\n",
    "train.to_csv(f\"data/adversarial_validation-{lang}-train.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
