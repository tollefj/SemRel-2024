{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial multilingual baseline (no training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'multilingual': 'FacebookAI/xlm-roberta-base',\n",
       " 'arq': 'CAMeL-Lab/bert-base-arabic-camelbert-da',\n",
       " 'amh': 'Davlan/xlm-roberta-base-finetuned-amharic',\n",
       " 'eng': 'FacebookAI/roberta-base',\n",
       " 'hau': 'Davlan/xlm-roberta-base-finetuned-hausa',\n",
       " 'kin': 'Davlan/xlm-roberta-base-finetuned-kinyarwanda',\n",
       " 'mar': 'l3cube-pune/marathi-roberta',\n",
       " 'ary': 'CAMeL-Lab/bert-base-arabic-camelbert-da',\n",
       " 'esp': 'PlanTL-GOB-ES/roberta-base-bne',\n",
       " 'tel': 'l3cube-pune/telugu-bert'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from models import models\n",
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tollef/git/STS-augmented-pair-encoder/pair_encoder/model.py:9: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['amh', 'arq', 'ary', 'eng', 'esp', 'hau', 'kin', 'mar', 'tel']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from util import get_langs\n",
    "langs = get_langs()\n",
    "langs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pair_encoder.evaluation import CorrelationEvaluator, get_correlation\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "from util import get_data, get_pairs, eval_and_submit\n",
    "\n",
    "def eval_lang(model, lang, save_name, model_name=\"default\"):\n",
    "    data = {\n",
    "        \"dev\": get_pairs(get_data(lang=lang, train=False)),\n",
    "        \"test\": get_pairs(get_data(lang=lang, test=True))\n",
    "    }\n",
    "    correlations = {\n",
    "        \"dev\": get_correlation(test=data[\"dev\"], pair_encoder=model),\n",
    "        \"test\": get_correlation(test=data[\"test\"], pair_encoder=model)\n",
    "    }\n",
    "    eval_and_submit(\n",
    "        pair_encoder=model,\n",
    "        lang=lang,\n",
    "        model_name=model_name,\n",
    "        timestamp=f\"{lang}-test-{save_name}\",\n",
    "        evaluation_phase=True\n",
    "    )\n",
    "    return correlations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at Davlan/xlm-roberta-base-finetuned-amharic and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving submission to submissions/amh-test-CUSTOMMODEL-notrain/pred_amh_a.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at CAMeL-Lab/bert-base-arabic-camelbert-da and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving submission to submissions/arq-test-CUSTOMMODEL-notrain/pred_arq_a.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at CAMeL-Lab/bert-base-arabic-camelbert-da and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving submission to submissions/ary-test-CUSTOMMODEL-notrain/pred_ary_a.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at FacebookAI/roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving submission to submissions/eng-test-CUSTOMMODEL-notrain/pred_eng_a.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at PlanTL-GOB-ES/roberta-base-bne and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/tollef/.local/lib/python3.10/site-packages/scipy/stats/_stats_py.py:5445: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(stats.ConstantInputWarning(warn_msg))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving submission to submissions/esp-test-CUSTOMMODEL-notrain/pred_esp_a.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at Davlan/xlm-roberta-base-finetuned-hausa and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving submission to submissions/hau-test-CUSTOMMODEL-notrain/pred_hau_a.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at Davlan/xlm-roberta-base-finetuned-kinyarwanda and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving submission to submissions/kin-test-CUSTOMMODEL-notrain/pred_kin_a.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at l3cube-pune/marathi-roberta and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving submission to submissions/mar-test-CUSTOMMODEL-notrain/pred_mar_a.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at l3cube-pune/telugu-bert and are newly initialized: ['classifier.bias', 'bert.pooler.dense.weight', 'classifier.weight', 'bert.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving submission to submissions/tel-test-CUSTOMMODEL-notrain/pred_tel_a.csv\n"
     ]
    }
   ],
   "source": [
    "from pair_encoder.model import PairEncoder\n",
    "\n",
    "baseline_no_train = {}\n",
    "for lang in langs:\n",
    "    model_name = models[lang]\n",
    "    model = PairEncoder(\n",
    "        model_name=model_name, max_length=200, device=\"cuda\", seed=42\n",
    "    )\n",
    "    baseline_no_train[lang] = eval_lang(\n",
    "        model, lang, save_name=f\"CUSTOMMODEL-notrain\", model_name=model_name\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'amh': {'dev': 0.1965079646056153, 'test': 0.20400322691324638},\n",
       " 'arq': {'dev': 0.04756816761282438, 'test': -0.10968241612417946},\n",
       " 'ary': {'dev': -0.1974865817391526, 'test': -0.019093196690484614},\n",
       " 'eng': {'dev': 0.10982817158298783, 'test': 0.10086046114317106},\n",
       " 'esp': {'dev': 0.12803685538883136, 'test': nan},\n",
       " 'hau': {'dev': 0.12951205532589663, 'test': 0.09523402829976144},\n",
       " 'kin': {'dev': 0.07085512968009423, 'test': 0.1434704633236933},\n",
       " 'mar': {'dev': -0.09905291597552086, 'test': -0.03348792211518759},\n",
       " 'tel': {'dev': 0.18360119164375752, 'test': 0.08402836706011647}}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_no_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>amh</th>\n",
       "      <th>arq</th>\n",
       "      <th>ary</th>\n",
       "      <th>eng</th>\n",
       "      <th>esp</th>\n",
       "      <th>hau</th>\n",
       "      <th>kin</th>\n",
       "      <th>mar</th>\n",
       "      <th>tel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>custom-notrain_dev</th>\n",
       "      <td>0.196508</td>\n",
       "      <td>0.047568</td>\n",
       "      <td>-0.197487</td>\n",
       "      <td>0.109828</td>\n",
       "      <td>0.128037</td>\n",
       "      <td>0.129512</td>\n",
       "      <td>0.070855</td>\n",
       "      <td>-0.099053</td>\n",
       "      <td>0.183601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>custom-notrain_test</th>\n",
       "      <td>0.204003</td>\n",
       "      <td>-0.109682</td>\n",
       "      <td>-0.019093</td>\n",
       "      <td>0.100860</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.095234</td>\n",
       "      <td>0.143470</td>\n",
       "      <td>-0.033488</td>\n",
       "      <td>0.084028</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          amh       arq       ary       eng       esp  \\\n",
       "custom-notrain_dev   0.196508  0.047568 -0.197487  0.109828  0.128037   \n",
       "custom-notrain_test  0.204003 -0.109682 -0.019093  0.100860       NaN   \n",
       "\n",
       "                          hau       kin       mar       tel  \n",
       "custom-notrain_dev   0.129512  0.070855 -0.099053  0.183601  \n",
       "custom-notrain_test  0.095234  0.143470 -0.033488  0.084028  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_baseline_notrain = pd.DataFrame(baseline_no_train).T\n",
    "df_prefix = \"custom-notrain\"\n",
    "df_baseline_notrain.columns = [f\"{df_prefix}_{c}\" for c in df_baseline_notrain.columns]\n",
    "df_baseline_notrain.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train per language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pair_encoder import train_encoder\n",
    "\n",
    "baseline_train_lang = {}\n",
    "\n",
    "K = 0\n",
    "\n",
    "for lang in langs:\n",
    "    print(f\"Training on {lang}...\")\n",
    "    lang_train = get_data(lang=lang, train=True)\n",
    "    lang_dev = get_data(lang=lang, train=False)\n",
    "\n",
    "    train_pairs = get_pairs(lang_train)\n",
    "    eval_pairs = get_pairs(lang_dev)\n",
    "    evaluator = CorrelationEvaluator.load(eval_pairs)\n",
    "    \n",
    "    model_name = models[lang]\n",
    "    print(f\"Using model {model_name} for {lang}...\")\n",
    "\n",
    "    encoder, _ = train_encoder(\n",
    "        train_samples=train_pairs,\n",
    "        upscaling_samples=None,\n",
    "        evaluator=evaluator,\n",
    "        timestamp=f\"{model_name}-train-{lang}\",\n",
    "        model_name=model_name,\n",
    "        similarity_model=None,\n",
    "        batch_size=32,\n",
    "        learning_rate=2e-5,\n",
    "        max_grad_norm=1.0,\n",
    "        epochs=5,\n",
    "        eval_steps=0,\n",
    "        max_length=200,\n",
    "        k=K,\n",
    "        weak_training_epochs=2,  # used if k > 0\n",
    "        seed=42,\n",
    "        save_to=None,\n",
    "        verbose=True,\n",
    "        device=\"cuda\"\n",
    "    )\n",
    "    \n",
    "    baseline_train_lang[lang] = eval_lang(encoder, lang, save_name=\"baseline-train-{lang}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "del encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>amh</th>\n",
       "      <th>arq</th>\n",
       "      <th>ary</th>\n",
       "      <th>eng</th>\n",
       "      <th>esp</th>\n",
       "      <th>hau</th>\n",
       "      <th>kin</th>\n",
       "      <th>mar</th>\n",
       "      <th>tel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>custom-lang_dev</th>\n",
       "      <td>0.859037</td>\n",
       "      <td>0.388998</td>\n",
       "      <td>0.814276</td>\n",
       "      <td>0.827910</td>\n",
       "      <td>0.682295</td>\n",
       "      <td>0.759853</td>\n",
       "      <td>0.647343</td>\n",
       "      <td>0.847262</td>\n",
       "      <td>0.807446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>custom-lang_test</th>\n",
       "      <td>0.805567</td>\n",
       "      <td>0.400398</td>\n",
       "      <td>0.811523</td>\n",
       "      <td>0.833139</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.687901</td>\n",
       "      <td>0.720887</td>\n",
       "      <td>0.861041</td>\n",
       "      <td>0.834647</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       amh       arq       ary       eng       esp       hau  \\\n",
       "custom-lang_dev   0.859037  0.388998  0.814276  0.827910  0.682295  0.759853   \n",
       "custom-lang_test  0.805567  0.400398  0.811523  0.833139       NaN  0.687901   \n",
       "\n",
       "                       kin       mar       tel  \n",
       "custom-lang_dev   0.647343  0.847262  0.807446  \n",
       "custom-lang_test  0.720887  0.861041  0.834647  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_baseline_lang = pd.DataFrame(baseline_train_lang).T\n",
    "df_prefix = \"custom-lang\"\n",
    "df_baseline_lang.columns = [f\"{df_prefix}_{c}\" for c in df_baseline_lang.columns]\n",
    "df_baseline_lang.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>amh</th>\n",
       "      <th>arq</th>\n",
       "      <th>ary</th>\n",
       "      <th>eng</th>\n",
       "      <th>esp</th>\n",
       "      <th>hau</th>\n",
       "      <th>kin</th>\n",
       "      <th>mar</th>\n",
       "      <th>tel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>custom-notrain_dev</th>\n",
       "      <td>0.196508</td>\n",
       "      <td>0.047568</td>\n",
       "      <td>-0.197487</td>\n",
       "      <td>0.109828</td>\n",
       "      <td>0.128037</td>\n",
       "      <td>0.129512</td>\n",
       "      <td>0.070855</td>\n",
       "      <td>-0.099053</td>\n",
       "      <td>0.183601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>custom-notrain_test</th>\n",
       "      <td>0.204003</td>\n",
       "      <td>-0.109682</td>\n",
       "      <td>-0.019093</td>\n",
       "      <td>0.100860</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.095234</td>\n",
       "      <td>0.143470</td>\n",
       "      <td>-0.033488</td>\n",
       "      <td>0.084028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>custom-lang_dev</th>\n",
       "      <td>0.859037</td>\n",
       "      <td>0.388998</td>\n",
       "      <td>0.814276</td>\n",
       "      <td>0.827910</td>\n",
       "      <td>0.682295</td>\n",
       "      <td>0.759853</td>\n",
       "      <td>0.647343</td>\n",
       "      <td>0.847262</td>\n",
       "      <td>0.807446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>custom-lang_test</th>\n",
       "      <td>0.805567</td>\n",
       "      <td>0.400398</td>\n",
       "      <td>0.811523</td>\n",
       "      <td>0.833139</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.687901</td>\n",
       "      <td>0.720887</td>\n",
       "      <td>0.861041</td>\n",
       "      <td>0.834647</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          amh       arq       ary       eng       esp  \\\n",
       "custom-notrain_dev   0.196508  0.047568 -0.197487  0.109828  0.128037   \n",
       "custom-notrain_test  0.204003 -0.109682 -0.019093  0.100860       NaN   \n",
       "custom-lang_dev      0.859037  0.388998  0.814276  0.827910  0.682295   \n",
       "custom-lang_test     0.805567  0.400398  0.811523  0.833139       NaN   \n",
       "\n",
       "                          hau       kin       mar       tel  \n",
       "custom-notrain_dev   0.129512  0.070855 -0.099053  0.183601  \n",
       "custom-notrain_test  0.095234  0.143470 -0.033488  0.084028  \n",
       "custom-lang_dev      0.759853  0.647343  0.847262  0.807446  \n",
       "custom-lang_test     0.687901  0.720887  0.861041  0.834647  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df = pd.concat([df_baseline_notrain.T, df_baseline_lang.T], axis=0)\n",
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>amh</th>\n",
       "      <th>arq</th>\n",
       "      <th>ary</th>\n",
       "      <th>eng</th>\n",
       "      <th>esp</th>\n",
       "      <th>hau</th>\n",
       "      <th>kin</th>\n",
       "      <th>mar</th>\n",
       "      <th>tel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>custom-notrain_dev</th>\n",
       "      <td>0.196508</td>\n",
       "      <td>0.047568</td>\n",
       "      <td>-0.197487</td>\n",
       "      <td>0.109828</td>\n",
       "      <td>0.128037</td>\n",
       "      <td>0.129512</td>\n",
       "      <td>0.070855</td>\n",
       "      <td>-0.099053</td>\n",
       "      <td>0.183601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>custom-notrain_test</th>\n",
       "      <td>0.204003</td>\n",
       "      <td>-0.109682</td>\n",
       "      <td>-0.019093</td>\n",
       "      <td>0.100860</td>\n",
       "      <td>-0.033540</td>\n",
       "      <td>0.095234</td>\n",
       "      <td>0.143470</td>\n",
       "      <td>-0.033488</td>\n",
       "      <td>0.084028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>custom-lang_dev</th>\n",
       "      <td>0.859037</td>\n",
       "      <td>0.388998</td>\n",
       "      <td>0.814276</td>\n",
       "      <td>0.827910</td>\n",
       "      <td>0.682295</td>\n",
       "      <td>0.759853</td>\n",
       "      <td>0.647343</td>\n",
       "      <td>0.847262</td>\n",
       "      <td>0.807446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>custom-lang_test</th>\n",
       "      <td>0.805567</td>\n",
       "      <td>0.400398</td>\n",
       "      <td>0.811523</td>\n",
       "      <td>0.833139</td>\n",
       "      <td>0.720519</td>\n",
       "      <td>0.687901</td>\n",
       "      <td>0.720887</td>\n",
       "      <td>0.861041</td>\n",
       "      <td>0.834647</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          amh       arq       ary       eng       esp  \\\n",
       "custom-notrain_dev   0.196508  0.047568 -0.197487  0.109828  0.128037   \n",
       "custom-notrain_test  0.204003 -0.109682 -0.019093  0.100860 -0.033540   \n",
       "custom-lang_dev      0.859037  0.388998  0.814276  0.827910  0.682295   \n",
       "custom-lang_test     0.805567  0.400398  0.811523  0.833139  0.720519   \n",
       "\n",
       "                          hau       kin       mar       tel  \n",
       "custom-notrain_dev   0.129512  0.070855 -0.099053  0.183601  \n",
       "custom-notrain_test  0.095234  0.143470 -0.033488  0.084028  \n",
       "custom-lang_dev      0.759853  0.647343  0.847262  0.807446  \n",
       "custom-lang_test     0.687901  0.720887  0.861041  0.834647  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# update esp values from codalab\n",
    "final_df.loc[\"custom-notrain_test\", \"esp\"] = \t-0.033539733\n",
    "final_df.loc[\"custom-lang_test\", \"esp\"] = 0.720519\n",
    "\n",
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>amh</th>\n",
       "      <th>arq</th>\n",
       "      <th>ary</th>\n",
       "      <th>eng</th>\n",
       "      <th>esp</th>\n",
       "      <th>hau</th>\n",
       "      <th>kin</th>\n",
       "      <th>mar</th>\n",
       "      <th>tel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>custom-notrain_dev</th>\n",
       "      <td>19.65</td>\n",
       "      <td>4.76</td>\n",
       "      <td>-19.75</td>\n",
       "      <td>10.98</td>\n",
       "      <td>12.80</td>\n",
       "      <td>12.95</td>\n",
       "      <td>7.09</td>\n",
       "      <td>-9.91</td>\n",
       "      <td>18.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>custom-notrain_test</th>\n",
       "      <td>20.40</td>\n",
       "      <td>-10.97</td>\n",
       "      <td>-1.91</td>\n",
       "      <td>10.09</td>\n",
       "      <td>-3.35</td>\n",
       "      <td>9.52</td>\n",
       "      <td>14.35</td>\n",
       "      <td>-3.35</td>\n",
       "      <td>8.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>custom-lang_dev</th>\n",
       "      <td>85.90</td>\n",
       "      <td>38.90</td>\n",
       "      <td>81.43</td>\n",
       "      <td>82.79</td>\n",
       "      <td>68.23</td>\n",
       "      <td>75.99</td>\n",
       "      <td>64.73</td>\n",
       "      <td>84.73</td>\n",
       "      <td>80.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>custom-lang_test</th>\n",
       "      <td>80.56</td>\n",
       "      <td>40.04</td>\n",
       "      <td>81.15</td>\n",
       "      <td>83.31</td>\n",
       "      <td>72.05</td>\n",
       "      <td>68.79</td>\n",
       "      <td>72.09</td>\n",
       "      <td>86.10</td>\n",
       "      <td>83.46</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       amh    arq    ary    eng    esp    hau    kin    mar  \\\n",
       "custom-notrain_dev   19.65   4.76 -19.75  10.98  12.80  12.95   7.09  -9.91   \n",
       "custom-notrain_test  20.40 -10.97  -1.91  10.09  -3.35   9.52  14.35  -3.35   \n",
       "custom-lang_dev      85.90  38.90  81.43  82.79  68.23  75.99  64.73  84.73   \n",
       "custom-lang_test     80.56  40.04  81.15  83.31  72.05  68.79  72.09  86.10   \n",
       "\n",
       "                       tel  \n",
       "custom-notrain_dev   18.36  \n",
       "custom-notrain_test   8.40  \n",
       "custom-lang_dev      80.74  \n",
       "custom-lang_test     83.46  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df = final_df * 100\n",
    "final_df = final_df.applymap(lambda x: round(x, 2))\n",
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>arq</th>\n",
       "      <th>amh</th>\n",
       "      <th>eng</th>\n",
       "      <th>hau</th>\n",
       "      <th>kin</th>\n",
       "      <th>mar</th>\n",
       "      <th>ary</th>\n",
       "      <th>esp</th>\n",
       "      <th>tel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>custom-notrain_dev</th>\n",
       "      <td>4.76</td>\n",
       "      <td>19.65</td>\n",
       "      <td>10.98</td>\n",
       "      <td>12.95</td>\n",
       "      <td>7.09</td>\n",
       "      <td>-9.91</td>\n",
       "      <td>-19.75</td>\n",
       "      <td>12.80</td>\n",
       "      <td>18.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>custom-notrain_test</th>\n",
       "      <td>-10.97</td>\n",
       "      <td>20.40</td>\n",
       "      <td>10.09</td>\n",
       "      <td>9.52</td>\n",
       "      <td>14.35</td>\n",
       "      <td>-3.35</td>\n",
       "      <td>-1.91</td>\n",
       "      <td>-3.35</td>\n",
       "      <td>8.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>custom-lang_dev</th>\n",
       "      <td>38.90</td>\n",
       "      <td>85.90</td>\n",
       "      <td>82.79</td>\n",
       "      <td>75.99</td>\n",
       "      <td>64.73</td>\n",
       "      <td>84.73</td>\n",
       "      <td>81.43</td>\n",
       "      <td>68.23</td>\n",
       "      <td>80.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>custom-lang_test</th>\n",
       "      <td>40.04</td>\n",
       "      <td>80.56</td>\n",
       "      <td>83.31</td>\n",
       "      <td>68.79</td>\n",
       "      <td>72.09</td>\n",
       "      <td>86.10</td>\n",
       "      <td>81.15</td>\n",
       "      <td>72.05</td>\n",
       "      <td>83.46</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       arq    amh    eng    hau    kin    mar    ary    esp  \\\n",
       "custom-notrain_dev    4.76  19.65  10.98  12.95   7.09  -9.91 -19.75  12.80   \n",
       "custom-notrain_test -10.97  20.40  10.09   9.52  14.35  -3.35  -1.91  -3.35   \n",
       "custom-lang_dev      38.90  85.90  82.79  75.99  64.73  84.73  81.43  68.23   \n",
       "custom-lang_test     40.04  80.56  83.31  68.79  72.09  86.10  81.15  72.05   \n",
       "\n",
       "                       tel  \n",
       "custom-notrain_dev   18.36  \n",
       "custom-notrain_test   8.40  \n",
       "custom-lang_dev      80.74  \n",
       "custom-lang_test     83.46  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# change order from\n",
    "# amh\tarq\tary\teng\tesp\thau\tkin\tmar\ttel\n",
    "# to \n",
    "# arq   & amh   & eng   & hau   & kin   & mar   & ary   & esp   & tel\n",
    "columns = [\n",
    "    \"arq\", \"amh\", \"eng\", \"hau\", \"kin\", \"mar\", \"ary\", \"esp\", \"tel\"\n",
    "]\n",
    "\n",
    "final_df = final_df[columns]\n",
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the df into dev and test, based on the last prefix\n",
    "index = \"base lang\".split()\n",
    "dev_df = final_df[final_df.index.str.contains(\"dev\")]\n",
    "dev_df.index = index\n",
    "\n",
    "test_df = final_df[final_df.index.str.contains(\"test\")]\n",
    "test_df.index = index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrrrrrrrr}\n",
      "\\toprule\n",
      " & arq & amh & eng & hau & kin & mar & ary & esp & tel \\\\\n",
      "\\midrule\n",
      "base & 4.76 & 19.65 & 10.98 & 12.95 & 7.09 & -9.91 & -19.75 & 12.80 & 18.36 \\\\\n",
      "lang & 38.90 & 85.90 & 82.79 & 75.99 & 64.73 & 84.73 & 81.43 & 68.23 & 80.74 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(dev_df.to_latex(float_format=\"%.2f\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrrrrrrrr}\n",
      "\\toprule\n",
      " & arq & amh & eng & hau & kin & mar & ary & esp & tel \\\\\n",
      "\\midrule\n",
      "base & -10.97 & 20.40 & 10.09 & 9.52 & 14.35 & -3.35 & -1.91 & -3.35 & 8.40 \\\\\n",
      "lang & 40.04 & 80.56 & 83.31 & 68.79 & 72.09 & 86.10 & 81.15 & 72.05 & 83.46 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(test_df.to_latex(float_format=\"%.2f\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
